# Abicom PPI - Scraper e Extrator de Tabela de Imagens

[![Vers√£o Python](https://img.shields.io/badge/python-3.8+-blue)](https://www.python.org/) [![Licen√ßa](https://img.shields.io/badge/License-MIT-yellow.svg)](#)

## 1. Sum√°rio

Coleta imagens de relat√≥rios PPI do site Abicom e extrai a primeira tabela detectada via OCR/an√°lise de layout, salvando-a como um arquivo CSV individual em `data/tabelas_por_mes/MM-YYYY/`.

**Desenvolvido por:** Lucas Lima <a href="https://www.linkedin.com/in/zukelima/" target="_blank" rel="noopener noreferrer"><img src="https://cdn-icons-png.flaticon.com/256/174/174857.png" alt="LinkedIn" width="24" height="24" style="vertical-align:middle;"></a>

## 2. Workflow B√°sico

1.  **Execu√ß√£o (`src/main.py`):** Orquestra as etapas via `python -m src.main`.
2.  **Scraping (`src/scrapers/abicom_scraper.py`):** Identifica URLs de posts/imagens.
3.  **Download/Verifica√ß√£o (`src/services/image_service.py`):** Baixa imagens novas, evita duplicatas (verifica√ß√£o de arquivos), organiza em `data/images/MM-YYYY/`.
4.  **An√°lise de Imagem (`src/analise_imagens.py`):** Processa imagens em `data/images/` (paralelamente): pr√©-processamento (opcional), extra√ß√£o da 1¬™ tabela (`img2table`/`easyocr`), tratamento de cabe√ßalho (`ffill`), salvamento do CSV individual em `data/tabelas_por_mes/MM-YYYY/`.
5.  **Relat√≥rio:** Exibe contagem de sucessos/falhas da an√°lise no console.

## 3. Componentes Principais

* **`src/main.py`:** Orquestrador do fluxo, `argparse`, config. logging.
* **`src/config.py`:** Constantes globais (URLs, Paths, Limites).
* **`src/scrapers/abicom_scraper.py`:** L√≥gica de scraping Abicom (`requests`, `bs4`).
* **`src/services/image_service.py`:** Gerencia download/verifica√ß√£o de imagens (sem DB).
* **`src/analise_imagens.py`:** L√≥gica de an√°lise (paralelismo, `Pillow`, `img2table`, `easyocr`, `pandas`, salvamento CSVs individuais).
* **`src/services/http_client.py`:** Cliente HTTP com re-tentativas (`requests.Session`).

## 4. Depend√™ncias Principais

* **Linguagem:** Python (>= 3.8)
* **Bibliotecas:** `requests`, `beautifulsoup4`, `Pillow`, `easyocr`, `img2table`, `pandas`, `numpy`, `torch`/`torchvision` (CPU), `concurrent.futures`, `logging`, `argparse`, `re`.

*(Consulte `requirements.txt`)*


## üèóÔ∏è 4. Estrutura do Projeto

```text
Abicom-WebScrapping-Project/
|
+-- .venv/                     # Ambiente Virtual Python (ex: python -m venv venv)
|
+-- .devcontainer/             # (Opcional) Configura√ß√£o VS Code + Docker
|   +-- devcontainer.json
|   +-- Dockerfile
+-- .vscode/                   # (Opcional) Configura√ß√µes VS Code
|   +-- settings.json
|
+-- src/                       # C√≥digo Fonte (Package 'src')
|   |-- __init__.py            # Inicializador do pacote
|   |-- config.py              # Configura√ß√µes globais (URLs, Paths, etc.)
|   |-- main.py                # Ponto de entrada principal (orquestra Scraper e An√°lise)
|   |-- analise_imagens.py     # L√≥gica de an√°lise (OCR, Extra√ß√£o, Salvar CSVs Indiv.) <-- Descri√ß√£o Atualizada
|   |-- models/                # Modelos de dados (dataclasses)
|   |   |-- __init__.py
|   |   |-- image.py           # Dataclass 'Image'
|   |-- services/              # Servi√ßos reutiliz√°veis
|   |   |-- __init__.py
|   |   |-- http_client.py     # Cliente HTTP com retentativas
|   |   |-- image_service.py   # Gerenciador de imagens (vers√£o sem DB)
|   |-- scrapers/              # Scrapers espec√≠ficos do site
|   |   |-- __init__.py
|   |   |-- base_scraper.py    # Classe base abstrata
|   |   |-- abicom_scraper.py  # Implementa√ß√£o para Abicom
|   |-- utils/                 # Fun√ß√µes utilit√°rias
|   |   |-- __init__.py
|   |   |-- file_utils.py      # Utilit√°rios de arquivo
|   |   |-- url_utils.py       # Utilit√°rios de URL
|
+-- data/                      # Diret√≥rio de Dados Gerados (Criado automaticamente)
|   |-- images/                # Imagens baixadas pelo scraper
|   |   |-- MM-YYYY/           # Organizadas por m√™s/ano (se habilitado)
|   |       |-- ppi-DD-MM-YYYY.jpg
|   |-- tabelas_por_mes/       # CSVs das tabelas individuais extra√≠das <-- ATUALIZADO
|   |   |-- MM-YYYY/           # Organizadas por m√™s/ano <-- ATUALIZADO
|   |       |-- ppi-DD-MM-YYYY_tabela.csv <-- ATUALIZADO
|   |-- error.log              # Log espec√≠fico de erros (ERROR/CRITICAL) <-- ADICIONADO/Confirmado
|
+-- requirements.txt           # Depend√™ncias Python
+-- scraper.log                # Log geral da execu√ß√£o (INFO/DEBUG)
+-- README.md                  # Documenta√ß√£o (Este arquivo)

```


## 5. ‚öôÔ∏è Instala√ß√£o

1.  **Pr√©-requisitos:** Python >= 3.8, `pip`, `git`.
2.  **Clone:** `git clone <URL_DO_SEU_REPOSITORIO> Abicom-WebScrapping-Project && cd Abicom-WebScrapping-Project`
3.  **Ambiente Virtual:** `python -m venv venv && source venv/bin/activate` (ou `.\venv\Scripts\activate` no Windows)
4.  **PyTorch (CPU):** √â crucial instalar a vers√£o correta **antes** do `easyocr`. Visite [pytorch.org](https://pytorch.org/), selecione: Stable, seu OS, Pip, Python, **CPU**. Copie e execute o comando `pip install` fornecido pelo site.
5.  **Depend√™ncias:** `pip install -r requirements.txt`.
    *(Nota: Verifique se `requirements.txt` est√° atualizado. `easyocr` baixar√° modelos na primeira execu√ß√£o. `img2table` pode requerer `opencv-python-headless` - `pip install opencv-python-headless`).*

## 6. Configura√ß√£o

* **Geral (`src/config.py`):** Ajuste constantes como `BASE_URL`, `MAX_PAGES`, `OUTPUT_DIR` (para imagens), `DATA_DIR` (para logs e tabelas), `SLEEP_*`, `IMAGE_EXTENSIONS`.
* **An√°lise (`src/analise_imagens.py`):** Ajuste constantes no topo do arquivo para otimiza√ß√£o:
    * `MAX_IMAGE_DIM_FOR_OCR`: Limite para redimensionamento pr√©-OCR (use `None` para desabilitar).
    * `CROP_BOX_MAIN_TABLE`: Coordenadas relativas `(esq, topo, dir, fundo)` para corte pr√©-OCR (use `None` para desabilitar). Requer testes.
    * Par√¢metros internos de `img2table.extract_tables()` (ex: `min_confidence`) podem ser ajustados dentro da fun√ß√£o `processar_e_salvar_tabela_individual`.

## 7. Utiliza√ß√£o

Execute os comandos a partir do **diret√≥rio raiz do projeto** com o `venv` ativado. Utilize `python -m` para garantir a correta resolu√ß√£o de pacotes.

* **Modo 1: Apenas Scraping** (Baixa/atualiza imagens em `data/images/`)
    ```bash
    python -m src.main
    ```

* **Modo 2: Scraping + An√°lise Completa** (Baixa/atualiza imagens, depois analisa todas e salva CSVs individuais em `data/tabelas_por_mes/`)
    ```bash
    python -m src.main --analyze
    # ou alias:
    python -m src.main -a
    ```

* **Modo 3: Apenas An√°lise** (Processa imagens existentes em `data/images/`, salva CSVs individuais em `data/tabelas_por_mes/`)
    * An√°lise paralela (padr√£o):
        ```bash
        python -m src.analise_imagens
        ```
    * An√°lise sequencial (1 worker, √∫til para debug):
        ```bash
        python -m src.analise_imagens -w 1
        ```
    * An√°lise de UMA imagem espec√≠fica (√≥timo para debug):
        ```bash
        python -m src.analise_imagens -i data/images/MM-YYYY/nome_da_imagem.jpg
        ```
        *(Substitua pelo caminho real)*
    * **Log Detalhado (DEBUG):** Adicione `-v` ou `--verbose` a qualquer comando `analise_imagens` ou `main`.

**Op√ß√µes de Linha de Comando (`python -m src.main`):**

* `--start-page N`: P√°gina inicial do scraping.
* `--max-pages N`: N√∫mero m√°ximo de p√°ginas a raspar.
* `--output-dir /path/`: Diret√≥rio de sa√≠da das **imagens**.
* `-v`, `--verbose`: Ativa log n√≠vel DEBUG.
* `-a`, `--analyze`: Executa a etapa de an√°lise ap√≥s o scraping (salva tabelas individuais).

## 8. Sa√≠da Gerada

* **Imagens:** `data/images/MM-YYYY/ppi-DD-MM-YYYY.jpg`
* **Tabelas Extra√≠das (CSV):** `data/tabelas_por_mes/MM-YYYY/ppi-DD-MM-YYYY_tabela.csv` (Cada arquivo cont√©m a primeira tabela extra√≠da da imagem correspondente, com cabe√ßalho tratado e usando `-` como separador).
* **Logs:**
    * `scraper.log`: Log geral (INFO ou DEBUG).
    * `data/error.log`: Log espec√≠fico de erros (ERROR/CRITICAL).

## 9. Limita√ß√µes e Pontos de Aten√ß√£o

* **Depend√™ncia do Website:** A estrutura HTML do site da Abicom pode mudar, exigindo ajustes no scraper (`src/scrapers/abicom_scraper.py`). A l√≥gica de detec√ß√£o de imagens pode precisar de revis√£o.
* **Precis√£o OCR/Extra√ß√£o:** A qualidade da extra√ß√£o depende das imagens e das bibliotecas (`easyocr`/`img2table`). Requer experimenta√ß√£o com os par√¢metros de pr√©-processamento e extra√ß√£o em `src/analise_imagens.py`.
* **Foco na Primeira Tabela:** Apenas a primeira tabela detectada por `img2table` √© processada e salva.
* **Performance CPU:** OCR √© intensivo. O tempo de an√°lise pode ser consider√°vel.
