# Abicom Web Scraper & Advanced Image Analyzer

![Demonstra√ß√£o](https://c.tenor.com/OjVjDqcWaIoAAAAd/tenor.gif)

## Vis√£o Geral

Este projeto automatiza completamente o processo de coleta e extra√ß√£o de dados de relat√≥rios di√°rios de Pre√ßo de Paridade de Importa√ß√£o (PPI) de combust√≠veis, publicados como imagens pela Abicom em seu site (`https://abicom.com.br/categoria/ppi/`). Ele supera os desafios da extra√ß√£o manual, transformando dados visuais complexos em informa√ß√µes estruturadas e prontas para an√°lise.

O pipeline consiste em duas etapas principais:
1.  **Web Scraping:** Coleta eficiente das imagens de relat√≥rio do site.
2.  **An√°lise de Imagem Avan√ßada:** Processamento paralelo das imagens para extrair metadados, propriedades e, crucialmente, dados tabulares espec√≠ficos usando OCR e an√°lise de layout.

**Desenvolvido por:** Zuke Lima <a href="https://www.linkedin.com/in/zukelima/" target="_blank" rel="noopener noreferrer"><img src="https://cdn-icons-png.flaticon.com/256/174/174857.png" alt="LinkedIn" width="24" height="24" style="vertical-align:middle;"></a>

---

## ‚ú® Funcionalidades Principais

### Web Scraping (`src/main.py` & M√≥dulos)

* **Coleta Focada:** Navega pela pagina√ß√£o da categoria PPI da Abicom, identificando e baixando apenas a imagem de relat√≥rio principal (`.jpg`/`.jpeg`) de cada post di√°rio.
* **Efici√™ncia:** Utiliza um `ImageService` que pr√©-indexa arquivos j√° baixados para **evitar downloads duplicados**, economizando tempo e banda.
* **Organiza√ß√£o:** Salva as imagens em uma estrutura l√≥gica de pastas por m√™s e ano (`data/images/MM-YYYY`) com nomes padronizados (`ppi-DD-MM-YYYY.jpg`).
* **Robustez:** Emprega um `HttpClient` customizado com `requests.Session`, retentativas autom√°ticas para erros de rede/timeout e headers apropriados.
* **Cortesia:** Inclui pausas configur√°veis (`time.sleep`) entre requisi√ß√µes para n√£o sobrecarregar o servidor da Abicom.

### An√°lise Avan√ßada de Imagens (`src/analise_imagens.py`)

* **Processamento Paralelo:** Usa `concurrent.futures.ProcessPoolExecutor` para analisar m√∫ltiplas imagens simultaneamente, otimizando drasticamente o tempo de execu√ß√£o em m√°quinas multi-core.
* **Extra√ß√£o de Metadados e Propriedades:** Utiliza `Pillow` para obter dimens√µes, modo de cor, formato da imagem e extrair dados EXIF (salvos como JSON na coluna `exif_data_json`).
* **Extra√ß√£o de Tabelas com IA (OCR + Layout):** Integra a biblioteca `img2table` com o motor OCR `easyocr` (configurado para pt/en) para **detectar e reconstruir as tabelas** presentes nas imagens, mesmo aquelas sem bordas expl√≠citas.
* **Extra√ß√£o de Valores Espec√≠ficos:** **Ponto chave do projeto:** Ap√≥s o `img2table` gerar um DataFrame para cada tabela encontrada, uma l√≥gica customizada (`find_indices_in_table`) analisa o *conte√∫do* desse DataFrame para localizar c√©lulas espec√≠ficas (cruzando localidade, tipo de combust√≠vel e m√©trica) e extrai os **valores num√©ricos correspondentes** (pre√ßos, defasagens R$, defasagens %).
* **Limpeza de Dados:** Inclui uma fun√ß√£o (`clean_numeric_value`) para tratar os valores extra√≠dos, removendo caracteres n√£o num√©ricos (R$, %), convertendo v√≠rgulas decimais para pontos e garantindo um formato num√©rico consistente (float).
* **Relat√≥rio CSV Estruturado:** Consolida todos os dados (metadados do arquivo, propriedades da imagem, EXIF JSON e **os valores num√©ricos espec√≠ficos extra√≠dos**) em um DataFrame `pandas` e o salva em um arquivo CSV timestamped (ex: `data/analise_valores_extraidos_YYYYMMDD_HHMMSS.csv`), pronto para an√°lise direta.

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python 3.8+
* **Web Scraping:** `requests`, `beautifulsoup4`
* **Processamento de Imagem:** `Pillow`
* **OCR:** `easyocr`
* **Extra√ß√£o de Tabelas:** `img2table`
* **Manipula√ß√£o de Dados:** `pandas`, `numpy`
* **Paralelismo:** `concurrent.futures`
* **Depend√™ncias AI:** `torch`, `torchvision`, `torchaudio` (para EasyOCR)
* **Utilit√°rios:** `logging`, `argparse`, `json`, `re`, `datetime`
* **Ambiente:** `venv` (recomendado), Docker (opcional)
* **Depend√™ncias Adicionais (prov√°veis):** `opencv-python-headless` (usado por `img2table`)

## üèóÔ∏è Estrutura do Projeto

```text
Abicom-WebScrapping-Project/
+-- .devcontainer/          # (Opcional) Configura√ß√£o VS Code + Docker
|   +-- devcontainer.json
|   +-- Dockerfile
+-- .vscode/                # (Opcional) Configura√ß√µes VS Code
|   +-- settings.json
+-- src/                    # C√≥digo fonte principal
|   +-- __init__.py
|   +-- config.py           # Configura√ß√µes globais
|   +-- main.py             # Ponto de entrada (Scraper + chamada da An√°lise)
|   +-- analise_imagens.py  # L√≥gica de an√°lise (Pillow, OCR, Tabela, Valores, CSV)
|   +-- models/             # Modelos de dados
|   |   +-- __init__.py
|   |   +-- image.py
|   +-- services/           # Servi√ßos
|   |   +-- __init__.py
|   |   +-- http_client.py
|   |   +-- image_service.py
|   +-- scrapers/           # Scrapers
|   |   +-- __init__.py
|   |   +-- base_scraper.py
|   |   +-- abicom_scraper.py
|   +-- utils/              # Utilit√°rios
|       +-- __init__.py
|       +-- file_utils.py
|       +-- url_utils.py
+-- data/                   # Dados gerados
|   +-- images/             # Imagens baixadas (ex: 04-2025/...)
|   +-- *.csv               # CSVs da an√°lise
+-- requirements.txt        # Depend√™ncias Python
+-- scraper.log             # Log da execu√ß√£o
+-- README.md               # Este arquivo

```

## ‚öôÔ∏è Instala√ß√£o e Configura√ß√£o

1.  **Clone o Reposit√≥rio:**
    ```bash
    git clone <URL_DO_SEU_REPOSITORIO>
    cd Abicom-WebScrapping-Project
    ```
2.  **Crie e Ative um Ambiente Virtual:**
    ```bash
    python -m venv venv
    # Windows: .\venv\Scripts\activate
    # Linux/macOS: source venv/bin/activate
    ```
3.  **Instale as Depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```
    *Nota:* `easyocr` pode precisar baixar modelos de linguagem na primeira execu√ß√£o da an√°lise. Certifique-se de ter conex√£o com a internet. `img2table` pode requerer `opencv-python-headless`.

4.  **(Opcional) Configure `src/config.py`:** Ajuste `OUTPUT_DIR`, `MAX_PAGES`, etc., se necess√°rio.

## üöÄ Como Usar

**Execute os comandos a partir da pasta raiz do projeto (`Abicom-WebScrapping-Project`).**

1.  **Apenas Baixar/Atualizar Imagens:**
    ```bash
    python -m src.main
    ```
    As imagens ser√£o salvas em `data/images/`.

2.  **Baixar/Atualizar Imagens E Executar An√°lise Completa:**
    ```bash
    python -m src.main --analyze
    ```
    Ap√≥s o scraping, a an√°lise ser√° executada. O CSV final (`analise_valores_extraidos_...csv`) ser√° salvo em `data/`.

3.  **Executar Apenas a An√°lise (em imagens j√° baixadas):**
    ```bash
    python src/analise_imagens.py
    ```
    Analisar√° as imagens em `data/images/` (ou conforme `config.py`) e gerar√° o CSV em `data/`.

**Op√ß√µes de Linha de Comando (`src/main.py`):**

* `--start-page N`: Define a p√°gina inicial do scraping.
* `--max-pages N`: Define o n√∫mero m√°ximo de p√°ginas a processar.
* `--output-dir /path/to/images`: Especifica o diret√≥rio para salvar imagens (o CSV vai para o diret√≥rio pai).
* `--verbose`: Ativa logs mais detalhados (n√≠vel DEBUG).
* `--analyze`: Executa a an√°lise completa (com OCR/extra√ß√£o de valores) ap√≥s o scraping.

## ‚ö†Ô∏è Notas Importantes e Limita√ß√µes

* **Depend√™ncia da Estrutura do Site:** O scraper depende da estrutura HTML atual da Abicom. Mudan√ßas no site podem quebr√°-lo.
* **Qualidade do OCR/Tabela:** A precis√£o da extra√ß√£o de tabelas (`img2table`) e do OCR (`easyocr`) depende da qualidade e consist√™ncia das imagens originais.
* **L√≥gica de Extra√ß√£o de Valores (`find_indices_in_table`):** Esta fun√ß√£o em `analise_imagens.py` √© **crucial** e **altamente dependente** do layout da tabela retornado pelo `img2table`. **√â muito prov√°vel que voc√™ precise inspecionar o DataFrame extra√≠do (adicionando prints tempor√°rios) e ajustar essa l√≥gica** para garantir que os valores corretos sejam localizados e extra√≠dos de forma confi√°vel para todas as varia√ß√µes de imagem.
* **Performance:** A an√°lise com OCR √© intensiva. O paralelismo acelera, mas processar milhares de imagens ainda levar√° tempo consider√°vel.
* **√âtica:** Use com responsabilidade. Respeite os Termos de Servi√ßo do site e evite sobrecarreg√°-lo (mantenha as pausas configuradas).